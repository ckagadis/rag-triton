version: "3.9"

services:
  triton:
    image: nvcr.io/nvidia/tritonserver:23.12-py3
    container_name: triton_server
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      # Mount your model repository (replace with your path)
      - ./models:/models
    command: >
      tritonserver
      --model-repository=/models
      --http-port=8000
      --grpc-port=8001
      --metrics-port=8002
    ports:
      - "8000:8000"   # HTTP endpoint
      - "8001:8001"   # gRPC endpoint
      - "8002:8002"   # Prometheus metrics
