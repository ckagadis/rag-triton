# ragmaster

**ragmaster** is a modular, containerized Retrieval-Augmented Generation (RAG) pipeline with **multimodal support**, **continual learning**, and **mandatory web search**.  

- Supports ingestion of all common document formats: images (PNG, JPG), PDFs, Word, Excel, PowerPoint, and plain text.  
- Integrates OCR and vision-language models for image-heavy content (e.g., comic pages).  
- Uses [SearxNG](https://github.com/searxng/searxng) for every query to ensure answers are always up to date.  
- Stores all knowledge (documents, web search results, user interactions) in **ChromaDB with persistent volumes**.  
- Runs **vLLM** for efficient GPU-accelerated inference.  
- Modular design: each service runs in its own container and communicates over well-defined APIs.  

---

## ğŸš€ First-Time Setup

After cloning the repository, run the following script to enable Git hooks:

```bash
./scripts/setup-githooks.sh
```

This ensures the **project tree in this README** is automatically updated on every commit.  

---

## ğŸ³ Running the Pipeline

Start all services with:

```bash
docker compose up --build
```

This will spin up all components: ingestion, OCR, embeddings, vision models, web search (SearxNG), ChromaDB, vLLM, backend, and the web UI.  

---

## ğŸ“‚ Project Tree

The following section is automatically updated before each commit:

<!-- PROJECT TREE START -->
```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .githooks
â”‚Â Â  â””â”€â”€ pre-commit
â”œâ”€â”€ rag-backend
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-chromadb
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-embedder
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-ingestion
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ ragmaster
â”œâ”€â”€ rag-ner
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-ocr
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-vision
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-vllm
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-websearch
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ rag-webui
â”‚Â Â  â””â”€â”€ README.md
â”œâ”€â”€ README.md
â””â”€â”€ scripts
    â””â”€â”€ setup-githooks.sh

14 directories, 14 files
```
<!-- PROJECT TREE END -->

---

## ğŸ§© Components

- **rag-backend** â€“ Orchestration layer (FastAPI).  
- **rag-ingestion** â€“ Document ingestion (PDF, Word, Excel, PowerPoint, text).  
- **rag-ocr** â€“ OCR service for image-based content.  
- **rag-vision** â€“ Vision-language embeddings (e.g., CLIP, BLIP, LLaVA).  
- **rag-embedder** â€“ Text embeddings (OCR output, web content, documents).  
- **rag-ner** â€“ Named entity and relation extraction.  
- **rag-websearch** â€“ SearxNG container (mandatory for every query).  
- **rag-vllm** â€“ vLLM GPU inference server.  
- **rag-webui** â€“ User-facing web interface.  
- **rag-chromadb** â€“ Vector database with persistent storage.  

---

## ğŸ”— Networking

- All containers are connected to a single custom Docker network: **`rag-master`**.  
- Communication between containers is **only allowed via HTTP APIs**.  
- No container can directly access anotherâ€™s filesystem or database.  
- This ensures modularity, reproducibility, and makes it easy to swap out components without breaking the rest of the pipeline.  

---

## ğŸ–¥ï¸ Hardware Used for Development & Testing

This repository was built and tested on the following hardware configuration:

- **Processor (CPU)**: Intel Core i9-13900KS (24-core, 32-thread, Raptor Lake, up to 6.0 GHz)  
- **Memory (RAM)**: 192GB CORSAIR Vengeance RGB DDR5  
- **Graphics Card (GPU)**: GIGABYTE AORUS GeForce RTX 5090 Master, 32GB GDDR7  
- **Motherboard**: GIGABYTE Z790 AORUS ELITE AX (LGA 1700, Intel Z790 chipset)  
- **Storage**: NVMe SSD (2TB recommended minimum for datasets, embeddings, and model weights) 

> âš ï¸ **Note**: Minimum hardware requirements will be specified once the core multimodal and LLM models are finalized. At present, this project has only been tested on the configuration listed above.

> âš ï¸ The system is designed for GPU acceleration. While most services will run on CPU-only setups, components such as **rag-vllm** and **rag-vision** require a modern NVIDIA GPU with sufficient VRAM for practical performance.  

### Minimum vs. Tested Hardware

| Component | Minimum | Recommended (tested) |
|-----------|----------|-----------------------|
| CPU       | 8 cores | Intel i9-13900KS (24 cores) |
| RAM       | 32GB | 192GB DDR5 |
| GPU       | NVIDIA RTX 3090 (24GB VRAM) | RTX 5090 (32GB VRAM) |
| Storage   | 500GB SSD | 2TB NVMe SSD |

---

## ğŸ“ Notes

- All containers, images, volumes, and directories use the `rag-` prefix for consistency.  
- Persistent Docker volumes are created for every service that needs long-term storage.  
- Web search results from SearxNG are always **embedded and persisted** in ChromaDB, so the system continually expands its knowledge.  
